---
permalink: /glossary/
title: "Glossary"
toc_label: " "
toc_icon: "star"
toc_sticky: true
toc: true
---

## Attention


## Context


## Downstream (Task)


## Fine-tune


## GPU
A GPU, or “graphics processing unit,” is a specialized electronic circuit for computer hardware.  Because GPUs allows for parallel processing, they are often used for intensive graphics rendering tasks, like gaming, video editing, and, increasingly, machine learning.

Working with the full-scale version of BERT typically requires access to a GPU. However, most Apple computers do not include GPUs. To use BERT on a computer without a GPU, researchers will typically either need to use a smaller BERT model, such as DistilBERT, or get access to a GPU through Google Colab (where they are offered for free) or through a computing cluster.

## Head


## Hidden States


## Hyperparameters


## Label


## Layers


## Task


## Transformers


## Token
A token is an individual instance of a word. For example, the sentence *"BERT is big and is also useful"* contains **seven** tokens.

## Type
A type is a unique string representation of a word. For example, the sentence *"BERT is big and is also useful"* contains **six** tokens.

## Vector
A vector is just a list of numbers. This is how we translate data for computers to understand. For example, we might translate a sentence in a vector (list) of word counts as input to a classifier.
